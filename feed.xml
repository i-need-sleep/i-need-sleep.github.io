<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://i-need-sleep.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://i-need-sleep.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-11-10T20:19:20+00:00</updated><id>https://i-need-sleep.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">How I Got Here</title><link href="https://i-need-sleep.github.io/blog/2023/how-i-got-here/" rel="alternate" type="text/html" title="How I Got Here"/><published>2023-10-13T10:51:21+00:00</published><updated>2023-10-13T10:51:21+00:00</updated><id>https://i-need-sleep.github.io/blog/2023/how-i-got-here</id><content type="html" xml:base="https://i-need-sleep.github.io/blog/2023/how-i-got-here/"><![CDATA[<p>Under construction LOL</p> <p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p> <h4 id="hipster-list">Hipster list</h4> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> <p>Hoodie Thundercats retro, tote bag 8-bit Godard craft beer gastropub. Truffaut Tumblr taxidermy, raw denim Kickstarter sartorial dreamcatcher. Quinoa chambray slow-carb salvia readymade, bicycle rights 90’s yr typewriter selfies letterpress cardigan vegan.</p> <hr/> <p>Pug heirloom High Life vinyl swag, single-origin coffee four dollar toast taxidermy reprehenderit fap distillery master cleanse locavore. Est anim sapiente leggings Brooklyn ea. Thundercats locavore excepteur veniam eiusmod. Raw denim Truffaut Schlitz, migas sapiente Portland VHS twee Bushwick Marfa typewriter retro id keytar.</p> <blockquote> We do not grow absolutely, chronologically. We grow sometimes in one dimension, and not in another, unevenly. We grow partially. We are relative. We are mature in one realm, childish in another. —Anais Nin </blockquote> <p>Fap aliqua qui, scenester pug Echo Park polaroid irony shabby chic ex cardigan church-key Odd Future accusamus. Blog stumptown sartorial squid, gastropub duis aesthetic Truffaut vero. Pinterest tilde twee, odio mumblecore jean shorts lumbersexual.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[description]]></summary></entry><entry><title type="html">Research Interest</title><link href="https://i-need-sleep.github.io/blog/2023/research-interest/" rel="alternate" type="text/html" title="Research Interest"/><published>2023-10-13T10:51:21+00:00</published><updated>2023-10-13T10:51:21+00:00</updated><id>https://i-need-sleep.github.io/blog/2023/research-interest</id><content type="html" xml:base="https://i-need-sleep.github.io/blog/2023/research-interest/"><![CDATA[<p>I am recently intrigued by these two topics: functional alignment and emergent concepts.</p> <h1 id="functional-alignment">Functional Alignment</h1> <p>Pretrained transformers are universal computation engines, and much of the internal reasoning/computation performed by pretrained models is agonistic to domains, tasks, languages and modalities. This is evidenced by the success of PEFT and, in particular, reprogramming methods where the same model (function) can be applied to different tasks with minor modifications in the inputs and outputs. In other words, profound commonalities exist between uni-modal functions, and these commonalities can be leveraged for functional alignment to improve data efficiency and enhance cross-modal interactions.</p> <p>Current multi-modal models are mostly trained by feature alignment (i.e. with parallel data) and are characteristically data-hungry due to the dimensionality of the feature space. Functional alignment (with similar uni-modal functions) can be an efficient alternative or complement. As a simple, unimodal example, consider the classic approaches to aligning cross-lingual word embeddings [FIG], where the alignment is based on small sets of word pairs and the “shapes” of monolingual embedding spaces. If we can leverage the edges between the words (i.e. have access to mono-lingual functions), alignment could be done with better accuracy and data efficiency.</p> <p>An additional benefit is finer and more principled cross-modal conditioning. Mappings between features of different modalities are lossy. [Show two shades of red and suggest they would both be mapped to the word “red”]. Current multi-modal LMs (e.g. GILL and Next-GPT) and diffusion models (e.g. CoDi) either use text LMs as backbones (trained on, e.g.image-caption pairs) or use text as the bridging modality. The intermediate modality (text) causes a bottleneck and prevents fine-grained multimodal control (e.g. preserving the exact colour of an object). Functional alignment offers an avenue to solve this issue (we can describe the second picture to be relatively darker). Of course, not all parts of the two functions can be exactly aligned. It would be ideal to extract, for instance, a “common language” between the textual and visual languages, which brings us to…</p> <h1 id="emergent-concepts">Emergent Concepts</h1> <p>By this, I mean extracting from self-supervised models series of intermediate representations or “concepts” that follow certain principles (e.g. being interpretable or interfaceable). Such principles are enforced by predefined priors (e.g. inductive biases or bottlenecks). Some priors, such as environments (multi-agent communication) and physical symmetry (a higher order inductive bias we have previously experimented with), tend to under-define the principles when handling high-dimensional, real-world data. Others, such as domain knowledge, tend to over-define it. Another issue with domain knowledge is that we do not always have well-defined internal structures. For instance, we do not have an intuitive, concise language for music beyond chord progressions and instrumentations. The learned internal concepts should be allowed to go beyond human knowledge but still be somewhat principled.</p> <p>Functional alignment offers a promising middle ground. It allows us to ask the question, “What are the parts of modality A that follow the principles of (are alignable with) modality B?”. By using a uni-modal function as a prior, we avoid using rigid human knowledge while still ensuring that the extracted representations have principles. This can then be used as an interpretable control interface where we know what can be controlled and what cannot. On a further note, this opens up possibilities for co-adaptative interfaces where human users learn to speak in emergent concepts and models learn to be aligned with human concepts.</p> <p>Note: How does using part-whole relationships (capsule networks) as a prior fit on the spectrum?</p> <h1 id="where-to-start">Where to Start</h1> <p>idontknowlol</p> <p>Easy case: nested modalities</p> <p>Post-hoc swapping of model components</p> <p>Merits: explicit(-ish) control, plug-and-play</p> <h1 id="going-further">Going Further</h1> <p>Immediately: growing trees! Adding width (audio -&gt; note + loudness) and adding depth (speech -&gt; text -&gt; emotion)</p> <p>Sequence alignment (diffusion, not ARLM)</p> <p>Layer alignment (need architectural work. How to feed probed reps back?)</p> <p>It’s too late I need to sleep</p> <p>How does this relate to all the fun research I’ve done? See &lt;a href=./blog/2023/research-interest&gt;How I Got Here&lt;/a&gt;.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[description]]></summary></entry><entry><title type="html">Post Template</title><link href="https://i-need-sleep.github.io/blog/2023/template/" rel="alternate" type="text/html" title="Post Template"/><published>2023-10-13T10:51:21+00:00</published><updated>2023-10-13T10:51:21+00:00</updated><id>https://i-need-sleep.github.io/blog/2023/template</id><content type="html" xml:base="https://i-need-sleep.github.io/blog/2023/template/"><![CDATA[<p>Under construction LOL</p> <p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p> <h4 id="hipster-list">Hipster list</h4> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> <p>Hoodie Thundercats retro, tote bag 8-bit Godard craft beer gastropub. Truffaut Tumblr taxidermy, raw denim Kickstarter sartorial dreamcatcher. Quinoa chambray slow-carb salvia readymade, bicycle rights 90’s yr typewriter selfies letterpress cardigan vegan.</p> <hr/> <p>Pug heirloom High Life vinyl swag, single-origin coffee four dollar toast taxidermy reprehenderit fap distillery master cleanse locavore. Est anim sapiente leggings Brooklyn ea. Thundercats locavore excepteur veniam eiusmod. Raw denim Truffaut Schlitz, migas sapiente Portland VHS twee Bushwick Marfa typewriter retro id keytar.</p> <blockquote> We do not grow absolutely, chronologically. We grow sometimes in one dimension, and not in another, unevenly. We grow partially. We are relative. We are mature in one realm, childish in another. —Anais Nin </blockquote> <p>Fap aliqua qui, scenester pug Echo Park polaroid irony shabby chic ex cardigan church-key Odd Future accusamus. Blog stumptown sartorial squid, gastropub duis aesthetic Truffaut vero. Pinterest tilde twee, odio mumblecore jean shorts lumbersexual.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[description]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://i-need-sleep.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://i-need-sleep.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://i-need-sleep.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[]]></content><author><name></name></author></entry></feed>