<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Yichen "William" Huang</title> <meta name="author" content="Yichen " william huang> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://i-need-sleep.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?3dd82e91913a2c1265c0f80e41ff39e2"></script> <script src="/assets/js/dark_mode.js?6458e63976eae16c0cbe86b97023895a"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <a id="top" class="ref_offset"></a> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/#top/"><span class="font-weight-bold">Yichen </span>"William" Huang</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/#top">About</a> </li> <li class="nav-item"> <a class="nav-link" href="/#about_publications">Publications</a> </li> <li class="nav-item"> <a class="nav-link" href="/#about_research">Other Research</a> </li> <li class="nav-item"> <a class="nav-link" href="/#about_misc">Misc</a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/cv.pdf"> CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <a id="eval_attack" style="display: block !important; position: relative !important; top: -90px !important; visibility: hidden !important;"></a> <div class="col-sm-2 abbr"></div> <div id="eval_attack" class="col-sm-8"> <div class="title">Robustness Tests for Automatic Machine Translation Metrics with Adversarial Attacks</div> <div class="venue">Accepted at EMNLP 2023 Findings (short paper)</div> <div class="author"> <em>Yichen Huang</em>, and Timothy Baldwin</div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="http://arxiv.org/abs/2311.00508" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/i-need-sleep/eval_attack" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">GitHub</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p> </p> <ul class="opened_tldr"> <li> MT metrics are inevitably used on out-of-distribution translations from unseen systems. We investigate the robustness of such metrics with off-the-shelf adversarial attacks. </li> <li> Our human evaluations validate that BERTScore, BLEURT and COMET tend to overpenalize adversarially-degraded texts, especially those associated with unseen, strong MT systems. </li> <li> We also devise a way to probe for self-inconsistency in distance-based metrics (e.g. BERTScore) without human ratings. </li> </ul> </div> </div> </div> </li> <li> <div class="row"> <a id="sps" style="display: block !important; position: relative !important; top: -90px !important; visibility: hidden !important;"></a> <div class="col-sm-2 abbr"></div> <div id="sps" class="col-sm-8"> <div class="title">Learning Interpretable Low-dimensional Representation via Physical Symmetry</div> <div class="venue">Accepted at NeurIPS 2023</div> <div class="author"> Xuanjie Liu, Daniel Chin, <em>Yichen Huang</em>, and Gus Xia</div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="http://arxiv.org/abs/2302.10890" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://recorder-v3.slideslive.com/#/share?share=89621&amp;s=d68940d6-b4f8-463d-95a0-4d0f05c887d0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/XuanjieLiu/Self-supervised-learning-via-symmetry" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">GitHub</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2302.10890"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p> </p> <ul class="opened_tldr"> <li> How can we learn low-dimensional, interpretable representations from perception (e.g. pitch from music audio) with minimal domain knowledge? What gives rise to these concepts in the first place? </li> <li> Physical symmetry as a fundamental inductive bias, implemented as a self-consistency constraint (e.g. the representation of pitch should be temporally transposition-equivariant). </li> <li> Our models learn linear pitch factors and 3D Cartesian coordinates in an unsupervised fashion. </li> <li> My part in this: Parts of experiments in Sec 4.1 (linear pitch factor). Design, implementation and writing for experiments in Secs A.4.2 (pitch-timbre disentanglement) and A.6.1 (SSL with arbitrary natural melodies). </li> </ul> </div> </div> </div> </li> <li> <div class="row"> <a id="referee" style="display: block !important; position: relative !important; top: -90px !important; visibility: hidden !important;"></a> <div class="col-sm-2 abbr"></div> <div id="referee" class="col-sm-8"> <div class="title">REFeREE: A REference-FREE Model-Based Metric for Text Simplification</div> <div class="venue">Under review</div> <div class="author"> <em>Yichen Huang</em>, and Ekaterina Kochmar</div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p> </p> <ul class="opened_tldr"> <li> Text simplification lacks a universal criterion of quality, and annotated references are costly. We propose a pretrained TS metric that can be fine-tuned to suit different quality standards. </li> <li> A 3-stage training curriculum: 1) Arbitrarily scalable pretraining on source-based objectives. 2) Pretraining on source-based and higher quality reference-based objectives. 3) Fine-tuning to specific criteria. </li> <li> Outperforms reference-based metrics in predicting overall quality and reaches competitive performance in predicting specific quality. </li> </ul> </div> </div> </div> </li> <li> <div class="row"> <a id="causal_lm_perf" style="display: block !important; position: relative !important; top: -90px !important; visibility: hidden !important;"></a> <div class="col-sm-2 abbr"></div> <div id="causal_lm_perf" class="col-sm-8"> <div class="title">Causal Discovery on the Capacities and Specifications of Large Language Models</div> <div class="venue">Course project for NLP 702: Advanced NLP</div> <div class="author"> <em>Yichen Huang</em>, Sathyamoorthy Rajendran, and Duy Khai Doan</div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://drive.google.com/file/d/1C-tBkOB5KGfP-zMwfgM88jwQxnh4cNMj/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://docs.google.com/presentation/d/1niVZYYKL4d2rfuEQg3aprmwADsOMZjbAr1FKQg-VdFA/edit?usp=sharing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> <a href="https://github.com/i-need-sleep/cd_llm_reasoning" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">GitHub</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p> </p> <ul class="opened_tldr"> <li> Can we establish causal relationships between LMs’ performances in different categories (e.g. better algebraic performance causing better performance in physics) and between the performances and LM specifications (e.g. more parameters causing better algebraic performance)? </li> <li> We apply off-the-shelf causal discovery algorithms on MMLU performances of 34 LMs. </li> <li> No strong evidence that performances on conceptually close subjects are causally related (e.g. high school/college computer science). </li> <li> Model size does not seem to causally determine the performances in all subjects. </li> </ul> </div> </div> </div> </li> <li> <div class="row"> <a id="juke_control" style="display: block !important; position: relative !important; top: -90px !important; visibility: hidden !important;"></a> <div class="col-sm-2 abbr"></div> <div id="juke_control" class="col-sm-8"> <div class="title">JukeControl: Enhancing Jukebox for Audio-to-Audio Music Generation with ControlNet</div> <div class="venue">Unpublished research, course project for NLP 703: Speech Processing</div> <div class="author"> <em>Yichen Huang</em>, and Gus Xia</div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://drive.google.com/file/d/1XXkyQjI9witQdy-Vt1leyyGf3pZL7LUB/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://docs.google.com/presentation/d/1qWf6590ScQTfmZxgcqlQ9h22QDf1MOJ2SpFPwagbMyk/edit?usp=sharing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> <a href="https://github.com/i-need-sleep/juke_control" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">GitHub</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p> </p> <ul class="opened_tldr"> <li> Modifying Jukebox’s top-level transformer prior model with ControlNet to enable audio-to-audio conditional generation. </li> <li> Early results on vocal-source separation, vocal-conditioned accompaniment generation and note-conditioned synthesis. </li> <li> Future work: recasting more tasks as audio-to-audio (e.g. Recasting conditions: performance rendering, instrumentation. Recasting outputs: transcription). </li> </ul> </div> </div> </div> </li> <li> <div class="row"> <a id="syntax_acquisition" style="display: block !important; position: relative !important; top: -90px !important; visibility: hidden !important;"></a> <div class="col-sm-2 abbr"></div> <div id="syntax_acquisition" class="col-sm-8"> <div class="title">BabyLM v.s. OpenWebText: How Does Child-Oriented Language Affect Syntax Acquisition for Language Models?</div> <div class="venue">Mini course project for NLP 705: Current Topics in NLP</div> <div class="author"> <em>Yichen Huang</em> </div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://drive.google.com/file/d/1zqrJiN5X5lKQ-UghDH9b5aSqqqM6Lnd0/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://docs.google.com/presentation/d/1xgWmb1GJo7o3V7nAbhli60p2P8y-QWAI2lqeHHS0is4/edit?usp=sharing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> <a href="https://github.com/i-need-sleep/syntax_acquisition" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">GitHub</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p> </p> <ul class="opened_tldr"> <li> Under the same small data budget, how does developmentally plausible data (child-oriented conversational texts) compare with web scraps in terms of LMs’ syntax acquisition? </li> <li> Our web-scrap-trained LM demonstrates stronger syntactic performance, the acquisition of which happens early on in the training process. </li> <li> Controlled experiments show that this superior performance is strongly associated with vocabulary and, to a lesser extent, with sentence length. </li> </ul> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <a id="dstc_uniter" style="display: block !important; position: relative !important; top: -90px !important; visibility: hidden !important;"></a> <div class="col-sm-2 abbr"></div> <div id="dstc_uniter" class="col-sm-8"> <div class="title">UNITER-Based Situated Coreference Resolution with Rich Multimodal Input</div> <div class="venue">DSTC10 workshop at AAAI 2022</div> <div class="author"> <em>Yichen Huang</em>, Yuchen Wang, and Yik-Cheung Tam</div> <div class="periodical"> 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="http://arxiv.org/abs/2112.03521" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/i-need-sleep/MMCoref_Cleaned" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">GitHub</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2112.03521"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p> </p> <ul class="opened_tldr"> <li> In a conversational situation, how can we determine which object is mentioned based on rich, multimodal information (text, vision and object knowledge base)? </li> <li> Based on a UNITER vision-language backbone, we inject dialogue, object and scene information through adaptors. </li> <li> We devise a method to encompass relative positions between objects through attention bias. </li> <li> Our solution ranks second in the official evaluation at DSTC10. </li> </ul> </div> </div> </div> </li> <li> <div class="row"> <a id="edit_polydis" style="display: block !important; position: relative !important; top: -90px !important; visibility: hidden !important;"></a> <div class="col-sm-2 abbr"></div> <div id="edit_polydis" class="col-sm-8"> <div class="title">Faster Sequence-to-Sequence Symbolic Music Generation with Rule-Augmented Edit-Based Models and Knowledge Distillation</div> <div class="venue">Unpublished research</div> <div class="author"> <em>Yichen Huang</em>, and Gus Xia</div> <div class="periodical"> 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://docs.google.com/presentation/d/1MxrjbSZzf7olBcJb2EZV0x2smDB-TAEbrB62FpSMIuQ/edit?usp=sharing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> <a href="https://github.com/i-need-sleep/quick_edit_polydis" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">GitHub</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p> </p> <ul class="opened_tldr"> <li> Specific tasks on symbolic music (e.g. harmonic style transfer) can be approximated with rule-based transformations and refined with minor edits. Can we use this property to accelerate autoregressive models for closer-to-real-time applications? </li> <li> Rule-based transformation + semi-autoregressive edit model with redesigned edit operations, trained with a distillation objective from a slower autoregressive model. </li> <li> Early experiments: 4x faster inference than the autoregressive teacher model, but there exists a large performance gap. </li> </ul> </div> </div> </div> </li> <li> <div class="row"> <a id="hst_interface" style="display: block !important; position: relative !important; top: -90px !important; visibility: hidden !important;"></a> <div class="col-sm-2 abbr"></div> <div id="hst_interface" class="col-sm-8"> <div class="title">An AI-Empowered Piano Performance Interface for Non-Pianists</div> <div class="venue">Unpublished research</div> <div class="author"> <em>Yichen Huang</em>, and Gus Xia</div> <div class="periodical"> 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://nime.pubpub.org/pub/axp76tok/draft?access=snqnq4sp" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PubPub</a> <a href="https://github.com/i-need-sleep/perf-interface" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">GitHub</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p> </p> <ul class="opened_tldr"> <li> Harmonic style transfer allows interactions with music based on high-level chord and texture controls. This can be leveraged to empower music amateurs. </li> <li> An intuitive real-time interface for piano performance and a guided explorative interface for learning. </li> <li> Small-scale user studies validate that our system is expressive and engages music skills. </li> </ul> </div> </div> </div> </li> <li> <div class="row"> &lt;a id= style="display: block !important; position: relative !important; top: -90px !important; visibility: hidden !important;"&gt;&lt;/a&gt; <div class="col-sm-2 abbr"></div> <div id="gaggia" class="col-sm-8"> <div class="title">A Frankensteined Gaggia Classic Pro</div> <div class="venue">Accepted on my kitchen counter, 2022</div> <div class="author"> <em>Yichen Huang</em>, and Daniel Chin</div> <div class="periodical"> 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p> </p> <ul class="opened_tldr"> <li> The Gaggia Classic Pro is an excellent budget single-boiler espresso machine. It, however, lacks precise monitoring and control for temperature and flow. </li> <li> We modified one such machine with a PID controller, pressure gauge, piggy-backed flow control knob, and several quality-of-life features, achieving consistently superior shot quality and outperforming budget single-boiler and heat exchanger baselines. </li> <li> Additionally, we implement an over-caffeination prevention mechanism where the pressure gauge’s connector starts to leak after the third consecutive shot. </li> </ul> <figure> <picture class="tldr_img"> <img src="/assets/img/gaggia.jpg" width="50%" onerror="this.onerror=null; $(’.responsive-img-srcset’).remove();"> </picture> </figure> </div> </div> </div> </li> <li> <div class="row"> &lt;a id= style="display: block !important; position: relative !important; top: -90px !important; visibility: hidden !important;"&gt;&lt;/a&gt; <div class="col-sm-2 abbr"></div> <div id="dubai_concert" class="col-sm-8"> <div class="title">Music X Lab led by Gus Xia: Expressive Music Performance with AI</div> <div class="venue">A concert at the Steinway Dubai Community Concert Hall</div> <div class="author"> Gus Xia, Ziyu Wang, Daniel Chin, <em>Yichen Huang</em>, and Other Music X Lab Members</div> <div class="periodical"> 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://www.youtube.com/watch?v=Ahfk0hvpCzM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">YouTube</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p> </p> <ul class="opened_tldr"> <li> A concert showcasing some of the earlier works at Music X Lab, including the piano interface. </li> <li> Gus made me program the UAE national anthem into the piano interface. </li> <li> The melody of the aforementioned anthem is stuck in my head to this day. </li> </ul> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <a id="hst_interface" style="display: block !important; position: relative !important; top: -90px !important; visibility: hidden !important;"></a> <div class="col-sm-2 abbr"></div> <div id="hst_interfacf" class="col-sm-8"> <div class="title">Meme Caption Generation</div> <div class="venue">Course project for CSCI-SHU 376: NLP</div> <div class="author"> <em>Yichen Huang</em>, and Yuchen Wang</div> <div class="periodical"> 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://raw.githubusercontent.com/Zacchaeus00/CSCI-376-Project-Implementation/main/nlp_final_report.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Zacchaeus00/CSCI-376-Project-Implementation" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">GitHub</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p> </p> <ul class="opened_tldr"> <li> Meme generation differes from general image captioning in that one image can have correspond to a diverse range of captions. How can we generate captions that are both specific and diverse? </li> <li> We propose a captioning pipeline with built-in stochasticities for diverse outputs and a CLIP-based reranking mechanism to ensure specificity. </li> </ul> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container" id="footer_container"> © Copyright 2023 Yichen Huang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: December 03, 2023. </div> <script type="text/javascript">for(var randomIndexUsed=[],counter=0,numberOfPosts=1,postsTitle=["Fun fact: My Erd\u0151s number is 4 (0. Paul Erd\u0151s, 1. Nick Wormald, 2. Alistair Moffat, 3. Timothy Baldwin).","Fun fact: If you refresh this page, you may see a different fun fact.","Fun fact: Despite the time we invested/wasted on the Frankensteined Gaggia machine, I no longer drink coffee on a daily basis for health concerns. Let me know if you want to adopt the surviving victim of our retrofitting procedure.","Fun fact: To this day, I have been getting away with not knowing how exactly Fourier transform works.","Fun fact: In summer, 2020, I spent 7 days to fully memorize a lexicon of 3,000 infrequent words for GRE (including a two-day break), arriving at a sub-GPT-4 performance of 168/170 (-1) in verbal reasoning. We anticipate a larger performance gap in retention.","Fun fact: I worked as a learning assistant for an introductory machine learning course in fall, 2021 where I once had the brilliant idea of holding a last-minute review session on the night before the midterm exam. The session had a attendance exceeding the actual lectures (40+ students), and I was kindly removed from the Academic Resouce Center for acpacity concerns.","Fun fact: The first time I attempted to train a language model (of music pitches), I forgot to offset the input sequence by one step and spent two weeks wondering why the model had perfect performance.","Fun fact: If you are wondering why the guitar parts in <a href=https://open.spotify.com/track/157aKxinSWtcaNuANQwSi0?si=ec62b4ca8b7c449c> \u4f55\u4e0d\u5192\u9669 </a> sound so bad, it's because I played them (I am greatful that HEKI tried very hard to make it sound better than it is, though).","Fun fact: One of the other fun facts is generated by Copilot. Can you guess which one it is?","Fun fact: I took a class in Chinese Science Fiction literature in spring, 2021, and I am now a proud owner of a copy of <a href=https://www.amazon.com/Three-Body-Problem-Cixin-Liu/dp/0765382032> The Three-Body Problem </a> signed by the author.","How is your diffusion model going today?"];counter<numberOfPosts;){var randomIndex,postTitle;randomIndex=Math.floor(Math.random()*postsTitle.length),"-1"==randomIndexUsed.indexOf(randomIndex)&&(postTitle=postsTitle[randomIndex],document.getElementById("footer_container").innerHTML+=counter==numberOfPosts-1?"<p><center>"+postTitle+"</center></p>":"<p><center>"+postTitle+"</center></p><hr />",randomIndexUsed.push(randomIndex),counter++)}</script> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>